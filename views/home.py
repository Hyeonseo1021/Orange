# -*- coding: utf-8 -*-
"""
í™ˆ í™”ë©´ - íŠœí„° ì¤‘ì‹¬ ë©”ì¸ í™”ë©´
"""

import streamlit as st
from datetime import datetime
from rag import get_rag_system
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import os
from dotenv import load_dotenv
from pathlib import Path

load_dotenv(dotenv_path=Path(__file__).resolve().parent.parent / ".env")

MODEL = os.getenv("MODEL", "qwen3-4b-2507")
BASE_URL = os.getenv("BASE_URL", "http://127.0.0.1:1234/v1")
API_KEY = os.getenv("API_KEY", "not-needed")

SYSTEM_PROMPT = """ë„ˆëŠ” 'ì˜¤ë Œì§€'ë¼ëŠ” í•™ìŠµ íŠœí„°ì•¼.

[ì—­í• ]
í•™ìŠµ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ëŠ” íŠœí„°.

[ì›ì¹™]
1. í•™ìŠµ ìë£Œì— ìˆëŠ” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´
2. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì†”ì§í•˜ê²Œ ë§í•´ì¤˜
3. ì–´ë ¤ìš´ ë‚´ìš©ì€ ì‰¬ìš´ ì˜ˆì‹œë¡œ ì„¤ëª…í•´
4. ë‹µë³€ì€ êµ¬ì¡°í™”í•´ì„œ ì½ê¸° ì‰½ê²Œ

[í•™ìŠµ ìë£Œ]
{context}
"""

QUICK_QUESTIONS = [
    "ì´ ê°œë… ì„¤ëª…í•´ì¤˜",
    "ì‰½ê²Œ ìš”ì•½í•´ì¤˜",
    "ì˜ˆì‹œ ë“¤ì–´ì¤˜",
    "í•µì‹¬ë§Œ ì •ë¦¬í•´ì¤˜"
]


def render():
    """í™ˆ í™”ë©´ ë Œë”ë§"""

    # ì‚¬ì´ë“œë°”
    _render_sidebar()

    # ë©”ì¸ ì˜ì—­
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if not st.session_state.messages:
        _render_greeting()
    else:
        _render_chat()


def _render_sidebar():
    """ì‚¬ì´ë“œë°” - ìë£Œ/í€´ì¦ˆ/ë³µìŠµ"""
    with st.sidebar:
        st.markdown("### ğŸŠ ì˜¤ë Œì§€ íŠœí„°")

        st.divider()

        # ìë£Œ ì¶”ê°€
        st.markdown("**ìë£Œ ì¶”ê°€**")
        uploaded = st.file_uploader(
            "íŒŒì¼ ì„ íƒ",
            type=["txt", "pdf", "png", "jpg"],
            label_visibility="collapsed"
        )
        if uploaded:
            if st.button("ì¶”ê°€", type="primary", use_container_width=True):
                _add_file(uploaded)

        # ì €ì¥ëœ ìë£Œ
        try:
            rag = get_rag_system()
            sources = rag.get_sources()
            if sources:
                st.markdown("**ì €ì¥ëœ ìë£Œ**")
                for s in sources[:5]:
                    st.caption(f"â€¢ {s}")
                if len(sources) > 5:
                    st.caption(f"ì™¸ {len(sources) - 5}ê°œ")

                if st.button("ìë£Œ ê´€ë¦¬", use_container_width=True):
                    st.session_state.current_page = "study"
                    st.rerun()
        except:
            pass

        st.divider()

        # í•™ìŠµ ë„êµ¬
        st.markdown("**í•™ìŠµ ë„êµ¬**")

        if st.button("í€´ì¦ˆ í’€ê¸°", use_container_width=True):
            st.session_state.current_page = "quiz"
            st.rerun()

        if st.button("ë³µìŠµ ë…¸íŠ¸", use_container_width=True):
            st.session_state.current_page = "review"
            st.rerun()

        st.divider()

        # í•™ìŠµ í˜„í™©
        stats = st.session_state.get("study_stats", {"studied": 0, "accuracy": 0, "review": 0})
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì§ˆë¬¸", stats["studied"])
        with col2:
            st.metric("ì •ë‹µë¥ ", f"{stats['accuracy']}%")


def _render_greeting():
    """íŠœí„° ì¸ì‚¬ í™”ë©´"""

    st.markdown("""
    <div class="tutor-greeting">
        <div class="tutor-avatar">ğŸŠ</div>
        <div class="tutor-message">ì•ˆë…•! ë‚˜ëŠ” ì˜¤ë Œì§€ì•¼</div>
        <div class="tutor-sub">ë¬´ì—‡ì´ë“  ë¬¼ì–´ë´, ê°™ì´ ê³µë¶€í•˜ì!</div>
    </div>
    """, unsafe_allow_html=True)

    # ë¹ ë¥¸ ì§ˆë¬¸
    st.markdown("<br>", unsafe_allow_html=True)
    cols = st.columns(4)
    for i, q in enumerate(QUICK_QUESTIONS):
        with cols[i]:
            if st.button(q, key=f"quick_{i}", use_container_width=True):
                st.session_state.messages.append({"role": "user", "content": q})
                st.rerun()

    # ì…ë ¥ì°½
    prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()


def _render_chat():
    """ì±„íŒ… í™”ë©´"""

    # ëŒ€í™” ê¸°ë¡
    for msg in st.session_state.messages:
        role = msg["role"]
        with st.chat_message(role, avatar="ğŸŠ" if role == "assistant" else None):
            st.markdown(msg["content"])

    # ì‘ë‹µ ìƒì„±
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        with st.chat_message("assistant", avatar="ğŸŠ"):
            response = _generate_response(st.session_state.messages[-1]["content"])
            st.session_state.messages.append({"role": "assistant", "content": response})

    # ì…ë ¥ì°½
    prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    # ìƒˆ ëŒ€í™” ë²„íŠ¼
    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ìƒˆ ëŒ€í™”", use_container_width=True):
            st.session_state.messages = []
            st.rerun()


def _generate_response(prompt: str) -> str:
    """LLM ì‘ë‹µ ìƒì„±"""
    context = ""
    try:
        rag = get_rag_system()
        docs = rag.search(prompt, k=3)
        if docs:
            context_parts = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata.get("source", "unknown")
                context_parts.append(f"[{i}] ({source})\n{doc.page_content}")
            context = "\n\n".join(context_parts)
    except:
        pass

    system_prompt = SYSTEM_PROMPT.format(
        context=context if context else "ë“±ë¡ëœ í•™ìŠµ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤."
    )

    chat_history = []
    for msg in st.session_state.messages[:-1]:
        if msg["role"] == "user":
            chat_history.append(HumanMessage(content=msg["content"]))
        else:
            chat_history.append(AIMessage(content=msg["content"]))
    chat_history = chat_history[-10:]

    llm = ChatOpenAI(
        model=MODEL,
        base_url=BASE_URL,
        api_key=API_KEY,
        temperature=0.4,
        streaming=True
    )

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{user_input}")
    ])

    chain = prompt_template | llm
    response_placeholder = st.empty()
    full_response = ""

    try:
        for chunk in chain.stream({
            "chat_history": chat_history,
            "user_input": prompt
        }):
            if chunk.content:
                full_response += chunk.content
                response_placeholder.markdown(full_response + " â–Œ")

        response_placeholder.markdown(full_response)
        add_study_history(f"ì§ˆë¬¸: {prompt[:20]}...")
        return full_response

    except Exception as e:
        error_msg = "ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´. LLM ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì¤˜!"
        response_placeholder.error(error_msg)
        return error_msg


def _add_file(uploaded):
    """ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ ì¶”ê°€"""
    try:
        rag = get_rag_system()
        name = uploaded.name
        ext = name.lower().split(".")[-1]

        with st.spinner("ì²˜ë¦¬ ì¤‘..."):
            if ext == "txt":
                content = uploaded.read().decode("utf-8")
                rag.add_document(content, metadata={"source": name, "type": "txt"})
            elif ext == "pdf":
                rag.add_pdf(uploaded, name, use_ocr=True)
            elif ext in ["png", "jpg", "jpeg"]:
                rag.add_image(uploaded, name)

        st.success(f"'{name}' ì¶”ê°€ë¨")
        add_study_history(f"ìë£Œ: {name}")
        st.rerun()

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")


def add_study_history(title: str):
    """í•™ìŠµ ê¸°ë¡ ì¶”ê°€"""
    if "study_history" not in st.session_state:
        st.session_state.study_history = []

    st.session_state.study_history.append({
        "date": datetime.now().strftime("%m/%d %H:%M"),
        "title": title
    })

    if "study_stats" not in st.session_state:
        st.session_state.study_stats = {"studied": 0, "accuracy": 0, "review": 0}
    st.session_state.study_stats["studied"] += 1
