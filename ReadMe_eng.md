# Real-time Streaming AI Chatbot (Flask + WebSocket)

This project is a chatbot application that displays responses from a local AI model in a real-time stream on a web UI. It uses Flask-SocketIO to implement real-time communication between the backend and the frontend.

-----

## ‚ú® Key Features

  * **Real-time Response Streaming**: Displays text generated by the AI in real-time, character by character, as if it were typing.
  * **WebSocket Communication**: Implements efficient, bidirectional communication between the server and client using Flask-SocketIO.
  * **Asynchronous Backend Processing**: Uses background tasks to prevent the server from blocking while waiting for the AI model's response.
  * **Sleek UI**: Provides a clean and responsive chat interface based on a dark mode theme.

-----

## üìÇ Project Structure

```
/chatbot-app
‚îú‚îÄ‚îÄ app.py              # Flask backend server
‚îú‚îÄ‚îÄ requirements.txt    # List of required Python libraries
‚îú‚îÄ‚îÄ functions/          # Functions called by the LLM
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html      # Frontend HTML
‚îî‚îÄ‚îÄ static/
    ‚îî‚îÄ‚îÄ style.css       # Frontend CSS
```

-----

## üöÄ Installation and Setup

### 1\. Prerequisites

  * **Python 3.8 or higher** must be installed.
  * A **local AI server** such as LM Studio or Ollama must be running (e.g., at `http://localhost:1234`).

### 2\. Clone and Set Up the Project

Download the project and navigate to its directory.

If you are using Git, you can download the project as follows:

```bash
git clone https://gitlab.ngrid.kr/root/class_software.git
cd chatbot-app
```

If you are not using Git, download the project as a zip file.

### 3\. Create and Activate a Virtual Environment

To install project dependencies in an isolated environment rather than system-wide, create and activate a virtual environment.

  * **macOS / Linux**:

    ```bash
    # Create a virtual environment named 'venv'
    python3 -m venv venv

    # Activate the virtual environment
    source venv/bin/activate
    ```

  * **Windows**:

    ```bash
    # Create a virtual environment named 'venv'
    python -m venv venv

    # Activate the virtual environment
    .\venv\Scripts\activate
    ```

    > üí° Once the virtual environment is activated, the terminal prompt will be prefixed with `(venv)`.

    > If you encounter an error creating the virtual environment, run PowerShell as an administrator and enter the following command:

    > ```powershell
    > Set-ExecutionPolicy RemoteSigned
    > ```

    > After entering the command above, type 'y' when prompted, and the error should be resolved.

### 4\. Install Dependencies

Install all the required libraries for the project using the `requirements.txt` file.

```bash
pip install -r requirements.txt
```

### 5\. Run the Application

1.  **Start your local AI server first.**
2.  Enter the following command in your terminal to start the Flask web server.
    ```bash
    python main.py
    ```
3.  Open a web browser and navigate to `http://127.0.0.1:8000` to launch the chatbot.

### 6\. Docker Build

```bash
docker build -t my-fastapi-app .
docker run -d -p 8000:8000 my-fastapi-app
```

-----

## ‚öôÔ∏è Deployment Notes

When deploying on Docker, the line `"http://127.0.0.1:1234/v1"` in `.env` file should be changed to `http://host.docker.internal:1234/v1`.

-----

## ‚öôÔ∏è How It Works

1.  **User Input (Frontend)**: The user types a message in the web UI and sends it.
2.  **WebSocket Message Transmission**: JavaScript sends the input message to the Flask backend via WebSocket (the `send_message` event).
3.  **Background Task Start (Backend)**: The Flask server receives the `send_message` event and starts a background task to request a response from the AI server.
4.  **AI Server Streaming Request**: The backend sends an HTTP POST request to the local AI server (`localhost:1234`) and receives the response as a stream.
5.  **Real-time Response Transmission**: As the backend receives response chunks (tokens) from the stream, it immediately sends them to the frontend via WebSocket (the `stream_response` event).
6.  **UI Update (Frontend)**: Each time JavaScript receives a `stream_response` event, it appends the text to the chat window, creating the real-time streaming effect.

-----

## üìÑ License

This project is licensed under the MIT License. For more details, see the `LICENSE` file.